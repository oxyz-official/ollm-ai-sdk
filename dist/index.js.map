{"version":3,"sources":["../src/index.ts","../src/ollm-provider.ts","../src/version.ts"],"sourcesContent":["export type {\n  OLLMChatModelId,\n  OLLMChatProviderOptions,\n} from './ollm-chat-options';\nexport type { OLLMCompletionModelId } from './ollm-completion-options';\nexport type {\n  OLLMEmbeddingModelId,\n  OLLMEmbeddingProviderOptions,\n} from './ollm-embedding-options';\nexport { ollm, createOLLM } from './ollm-provider';\nexport type {\n  OLLMProvider,\n  OLLMProviderSettings,\n  OLLMErrorData,\n} from './ollm-provider';\nexport { VERSION } from './version';\n\n","import {\n  OpenAICompatibleChatLanguageModel,\n  OpenAICompatibleCompletionLanguageModel,\n  ProviderErrorStructure,\n} from '@ai-sdk/openai-compatible';\nimport {\n  EmbeddingModelV3,\n  ImageModelV3,\n  LanguageModelV3,\n  NoSuchModelError,\n  ProviderV3,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  withoutTrailingSlash,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OLLMChatModelId } from './ollm-chat-options';\nimport { OLLMCompletionModelId } from './ollm-completion-options';\nimport { OLLMEmbeddingModelId } from './ollm-embedding-options';\nimport { VERSION } from './version';\n\nexport type OLLMErrorData = z.infer<typeof ollmErrorSchema>;\n\nconst ollmErrorSchema = z.object({\n  error: z.object({\n    message: z.string(),\n    type: z.string().optional(),\n    param: z.string().nullable().optional(),\n    code: z.string().nullable().optional(),\n  }),\n});\n\nconst ollmErrorStructure: ProviderErrorStructure<OLLMErrorData> = {\n  errorSchema: ollmErrorSchema,\n  errorToMessage: data => data.error.message,\n};\n\nexport interface OLLMProviderSettings {\n  /**\n   * OLLM API key. Default value is taken from the `OLLM_API_KEY`\n   * environment variable.\n   */\n  apiKey?: string;\n\n  /**\n   * Base URL for the OLLM API calls.\n   * @default 'http://localhost:4000/v1'\n   */\n  baseURL?: string;\n\n  /**\n   * Custom headers to include in the requests.\n   */\n  headers?: Record<string, string>;\n\n  /**\n   * Custom fetch implementation. You can use it as a middleware to intercept requests,\n   * or to provide a custom fetch implementation for e.g. testing.\n   */\n  fetch?: FetchFunction;\n}\n\nexport interface OLLMProvider extends ProviderV3 {\n  /**\n   * Creates a model for text generation.\n   */\n  (modelId: OLLMChatModelId): LanguageModelV3;\n\n  /**\n   * Creates a chat model for text generation.\n   */\n  chatModel(modelId: OLLMChatModelId): LanguageModelV3;\n\n  /**\n   * Creates a completion model for text generation.\n   */\n  completionModel(modelId: OLLMCompletionModelId): LanguageModelV3;\n\n  /**\n   * Creates a language model for text generation.\n   */\n  languageModel(modelId: OLLMChatModelId): LanguageModelV3;\n\n  /**\n   * Creates an embedding model for text embeddings.\n   */\n  embeddingModel(modelId: OLLMEmbeddingModelId): EmbeddingModelV3;\n\n  /**\n   * @deprecated Use `embeddingModel` instead.\n   */\n  textEmbeddingModel(modelId: OLLMEmbeddingModelId): EmbeddingModelV3;\n\n  /**\n   * Creates an image model.\n   * Note: OLLM does not natively support image generation models.\n   * This will throw a NoSuchModelError.\n   */\n  imageModel(modelId: string): ImageModelV3;\n}\n\nconst defaultBaseURL = 'http://localhost:4000/v1';\n\nexport function createOLLM(options: OLLMProviderSettings = {}): OLLMProvider {\n  const baseURL = withoutTrailingSlash(options.baseURL ?? defaultBaseURL);\n\n  const getHeaders = () =>\n    withUserAgentSuffix(\n      {\n        Authorization: `Bearer ${loadApiKey({\n          apiKey: options.apiKey,\n          environmentVariableName: 'OLLM_API_KEY',\n          description: 'OLLM API key',\n        })}`,\n        ...options.headers,\n      },\n      `ai-sdk/ollm/${VERSION}`,\n    );\n\n  interface CommonModelConfig {\n    provider: string;\n    url: ({ path }: { path: string }) => string;\n    headers: () => Record<string, string>;\n    fetch?: FetchFunction;\n  }\n\n  const getCommonModelConfig = (modelType: string): CommonModelConfig => ({\n    provider: `ollm.${modelType}`,\n    url: ({ path }) => `${baseURL}${path}`,\n    headers: getHeaders,\n    fetch: options.fetch,\n  });\n\n  const createChatModel = (modelId: OLLMChatModelId) => {\n    return new OpenAICompatibleChatLanguageModel(modelId, {\n      ...getCommonModelConfig('chat'),\n      errorStructure: ollmErrorStructure,\n    });\n  };\n\n  const createCompletionModel = (modelId: OLLMCompletionModelId) =>\n    new OpenAICompatibleCompletionLanguageModel(modelId, {\n      ...getCommonModelConfig('completion'),\n      errorStructure: ollmErrorStructure,\n    });\n\n  // OLLM does not support embedding models\n  const createEmbeddingModel = (modelId: OLLMEmbeddingModelId) => {\n    throw new NoSuchModelError({ modelId, modelType: 'embeddingModel' });\n  };\n\n  const provider = (modelId: OLLMChatModelId) => createChatModel(modelId);\n\n  provider.specificationVersion = 'v3' as const;\n  provider.completionModel = createCompletionModel;\n  provider.chatModel = createChatModel;\n  provider.languageModel = createChatModel;\n  provider.embeddingModel = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n\n  // OLLM doesn't have native image model support via OpenAI-compatible API\n  provider.imageModel = (modelId: string) => {\n    throw new NoSuchModelError({ modelId, modelType: 'imageModel' });\n  };\n\n  return provider;\n}\n\n/**\n * Default OLLM provider instance.\n */\nexport const ollm = createOLLM();\n","// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n\n"],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAA,+BAIO;AACP,sBAMO;AACP,4BAKO;AACP,gBAAkB;;;AChBX,IAAM,UACX,OACI,UACA;;;ADqBN,IAAM,kBAAkB,YAAE,OAAO;AAAA,EAC/B,OAAO,YAAE,OAAO;AAAA,IACd,SAAS,YAAE,OAAO;AAAA,IAClB,MAAM,YAAE,OAAO,EAAE,SAAS;AAAA,IAC1B,OAAO,YAAE,OAAO,EAAE,SAAS,EAAE,SAAS;AAAA,IACtC,MAAM,YAAE,OAAO,EAAE,SAAS,EAAE,SAAS;AAAA,EACvC,CAAC;AACH,CAAC;AAED,IAAM,qBAA4D;AAAA,EAChE,aAAa;AAAA,EACb,gBAAgB,UAAQ,KAAK,MAAM;AACrC;AAkEA,IAAM,iBAAiB;AAEhB,SAAS,WAAW,UAAgC,CAAC,GAAiB;AA1G7E;AA2GE,QAAM,cAAU,6CAAqB,aAAQ,YAAR,YAAmB,cAAc;AAEtE,QAAM,aAAa,UACjB;AAAA,IACE;AAAA,MACE,eAAe,cAAU,kCAAW;AAAA,QAClC,QAAQ,QAAQ;AAAA,QAChB,yBAAyB;AAAA,QACzB,aAAa;AAAA,MACf,CAAC,CAAC;AAAA,MACF,GAAG,QAAQ;AAAA,IACb;AAAA,IACA,eAAe,OAAO;AAAA,EACxB;AASF,QAAM,uBAAuB,CAAC,eAA0C;AAAA,IACtE,UAAU,QAAQ,SAAS;AAAA,IAC3B,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB;AAEA,QAAM,kBAAkB,CAAC,YAA6B;AACpD,WAAO,IAAI,2DAAkC,SAAS;AAAA,MACpD,GAAG,qBAAqB,MAAM;AAAA,MAC9B,gBAAgB;AAAA,IAClB,CAAC;AAAA,EACH;AAEA,QAAM,wBAAwB,CAAC,YAC7B,IAAI,iEAAwC,SAAS;AAAA,IACnD,GAAG,qBAAqB,YAAY;AAAA,IACpC,gBAAgB;AAAA,EAClB,CAAC;AAGH,QAAM,uBAAuB,CAAC,YAAkC;AAC9D,UAAM,IAAI,iCAAiB,EAAE,SAAS,WAAW,iBAAiB,CAAC;AAAA,EACrE;AAEA,QAAM,WAAW,CAAC,YAA6B,gBAAgB,OAAO;AAEtE,WAAS,uBAAuB;AAChC,WAAS,kBAAkB;AAC3B,WAAS,YAAY;AACrB,WAAS,gBAAgB;AACzB,WAAS,iBAAiB;AAC1B,WAAS,qBAAqB;AAG9B,WAAS,aAAa,CAAC,YAAoB;AACzC,UAAM,IAAI,iCAAiB,EAAE,SAAS,WAAW,aAAa,CAAC;AAAA,EACjE;AAEA,SAAO;AACT;AAKO,IAAM,OAAO,WAAW;","names":[]}